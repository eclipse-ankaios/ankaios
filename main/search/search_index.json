{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":""},{"location":"#eclipse-ankaios","title":"Eclipse Ankaios","text":"Watch Eclipse Ankaios presentation at Eclipse SDV community day on July 6, 2023 on Youtube"},{"location":"#scope","title":"Scope","text":"<p>Eclipse Ankaios provides workload and container orchestration for automotive High Performance Computing (HPC) software. While it can be used for various fields of applications, it is developed from scratch for automotive use cases and provides a slim yet powerful solution to manage containerized applications. It supports various container runtimes with Podman as the first one, but other container runtimes and even native applications can be supported. Eclipse Ankaios is independent of existing communication frameworks like SOME/IP, DDS, or REST API.</p> <p>Eclipse Ankaios manages multiple nodes and virtual machines with a single unique API in order to start, stop, configure, and update containers and workloads. It provides a central place to manage automotive applications with a setup consisting of one server and multiple agents. Usually one agent per node connects to one or more runtimes that are running the workloads.</p>"},{"location":"#next-steps","title":"Next steps","text":"<ul> <li>For first steps see installation and quickstart.</li> <li>An overview how Ankaios works is given on the architecture page.</li> <li>The API is described in the reference section.</li> <li>For contributions have a look at the development pages.</li> </ul>"},{"location":"#background","title":"Background","text":"<p>Eclipse Ankaios follows the UNIX philosophy to have one tool for one job and do that job well. It does not depend on a specific init system like systemd but can be started with any init system. It also does not handle persistency but can use  an existing automotive persistency handling, e.g. provided by AUTOSAR Adaptive.</p> <p>The workloads are provided access to the Eclipse Ankaios API using access control and thus are able to dynamically reconfigure the system. One possible use case is the dynamic startup of an application that is only required in a particular situation such as a parking assistant. When the driver wants to park the car, a control workload can start the parking assistant application. When the parking is finished, the parking assistant workload is stopped again.</p> <p>Eclipse Ankaios also provides a CLI that allows developers to develop and test configurations. In order to gain compatibility with Kubernetes, Eclipse Ankaios accepts pod specifications.</p> <p>An optional fleet connector can use the Eclipse Ankaios API to connect to a cloud-based software update system, which allows an OEM to manage a fleet of vehicles and provide new states to Eclipse Ankaios in order to update single or all applications.</p> <p>In order to support the Automotive SPICE process, Eclipse Ankaios comes with requirements tracing supported by OpenFastTrace.</p>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>Two executables are used for each Ankaios deployment: the Ankaios server and the Ankaios agent.</p> <p></p> <p>When started, the Ankaios server loads the configured startup state of the cluster and stores it as a desired state. To reach this desired state, the server instructs the Ankaios agents to start and stop workloads. Each Ankaios cluster runs exactly one instance of the Ankaios server making the server the single source of truth.</p> <p>A running instance of the Ankaios agent is present on every node where Ankaios needs to execute workloads. The Ankaios agent is responsible for starting and stopping workloads, according to the commands it gets from the Ankaios server.</p> <p>The Ankaios server itself does not run workloads directly so in order to start workloads on the node running the server, an Ankaios agent shall be started there too.</p> <p>Ankaios provides an interface, which allows workloads to change the desired state stored in the Ankaios server. Workloads access this interface by sending their requests to the Ankaios agent managing them. Each request is checked by the Ankaios agent and, on successful authorization, forwarded to the Ankaios server. This interface can be used to e.g.:</p> <ul> <li>Dynamically reconfigure the system to start a parking assistant.</li> <li>Start additional workloads requested by a backend to collect data about the road condition.</li> </ul> <p>In the diagram above one of the workloads on node 1 acts as fleet connector. It accesses a backend and forwards commands to the Ankaios server. In the example below the fleet connector gets an update from the backend, which adds a workload to node 2.</p> <p></p>"},{"location":"architecture/#notes","title":"Notes","text":"<ul> <li>Ankaios uses gRPC for communication between the Ankaios server and the Ankaios agents,   but the internal structure of Ankaios allows to replace gRPC with another communication protocol.</li> <li>The communication between workloads is not in the scope of Ankaios.   The communication must be set up separately,   which allows to use any technology needed for the project, e.g. network, named pipes, unix sockets or shared memory.</li> </ul>"},{"location":"support/","title":"Support","text":""},{"location":"support/#mailing-list","title":"Mailing list","text":"<p>Join our developer mailing list for up to date information or sending questions.</p>"},{"location":"support/#discussion-forum","title":"Discussion forum","text":"<p>If you have a general question, an idea or want to show how you use Ankaios, the discussion forum might be the right place for you.</p>"},{"location":"support/#issue","title":"Issue","text":"<p>For reporting bugs or suggesting enhancements a new issue should be created using one of the templates if possible.</p>"},{"location":"development/build/","title":"Build","text":""},{"location":"development/build/#dev-container","title":"Dev container","text":"<p>The repo provides a Visual Studio Code dev container which includes all necessary tools to build all components and the documentation, but it does not provide the tools to run Ankaios as it's not the target platform. In case you want to extend the dev container see extending the dev container.</p>"},{"location":"development/build/#prerequisites","title":"Prerequisites","text":"<p>As prerequisites, you need to have the following tools set up:</p> <ul> <li>Docker (Installation instructions)</li> <li>Visual Studio Code (Installation instructions)</li> <li>Microsoft's Visual Studio Code Extension Dev Containers</li> </ul>"},{"location":"development/build/#build-ankaios","title":"Build Ankaios","text":"<p>The following steps assume an x86_64 host. For Mac with Apple silicon, see chapter Build for arm64 target.</p> <p>To build and test the Ankaios agent and server, run the following command inside the dev container:</p> <pre><code>cargo build\n</code></pre> <p>and for release</p> <pre><code>cargo build --release\n</code></pre> <p>As Ankaios uses musl for static linking, the binaries will be located in <code>target/x86_64-unknown-linux-musl</code>.</p>"},{"location":"development/build/#build-for-arm64-target","title":"Build for arm64 target","text":"<p>The dev container adds required tools for <code>arm64</code> architecture. To build Ankaios for <code>arm64</code>, run the following command inside the dev container:</p> <pre><code>cargo build --target aarch64-unknown-linux-musl --release\n</code></pre> <p>Info</p> <p>When using a dev container on Mac with Apple silicon and the build fails, change the file sharing implementation in Docker Desktop. Goto Docker Desktop and <code>Settings</code>, then <code>General</code> and change the file sharing implementation from <code>VirtioFS</code> to <code>gRPC FUSE</code>. See also eclipse-ankaios/ankaios#147.</p>"},{"location":"development/ci-cd-release/","title":"CI/CD - Release","text":"<p>A release shall be built directly using the CI/CD environment GitHub Actions. The release build creates and uploads all necessary artifacts that are required for a release.</p>"},{"location":"development/ci-cd-release/#release-workflow","title":"Release workflow","text":"<p>For building a release a separate workflow exists inside <code>.github/workflows/release.yml</code>. The release workflow reuses the complete build workflow from <code>.github/workflows/build.yml</code> and its artifacts.</p> <p>This allows to avoid having to duplicate the steps of the build workflow into the release workflow and thus have a single point of change for the build workflow.</p> <p>The release workflow executes the build workflow, exports the build artifacts into an archive for each supported platform and uploads it to the GitHub release.</p> <p>As an example the following release artifacts are created for linux-amd64:</p> <ul> <li>ankaios-linux-amd64.tar.gz</li> <li>ankaios-linux-amd64.tar.gz.sha512sum.txt</li> </ul> <p>The tar.gz archive contains the pre-built binaries for the Ankaios CLI, Ankaios server and Ankaios agent. The *.sha512sum.txt file contains the sha-512 hash of the archive.</p>"},{"location":"development/ci-cd-release/#release-scripts","title":"Release scripts","text":"<p>To package the desired release artifacts a separate script <code>tools/create_release.sh</code> is called inside the release job. The script calls another script <code>tools/create_artifacts.sh</code> for each platform that creates the artifacts mentioned above.</p> <p>In addition, it exports the following:</p> <ul> <li>Coverage report</li> <li>ankaios.proto</li> <li>install.sh (Ankaios installation script)</li> </ul> <p>Within the release workflow the build artifacts are downloaded into a temporary folder called <code>dist</code> which has the following structure:</p> <pre><code>\u251c\u2500\u2500 coverage\n\u2502   \u251c\u2500\u2500 index.html\n\u2502   \u2514\u2500\u2500 style.css\n\u251c\u2500\u2500 linux-amd64\n\u2502   \u2514\u2500\u2500 bin\n\u2502       \u251c\u2500\u2500 ank\n\u2502       \u251c\u2500\u2500 ank-agent\n\u2502       \u2514\u2500\u2500 ank-server\n\u251c\u2500\u2500 linux-arm64\n\u2502   \u2514\u2500\u2500 bin\n\u2502       \u251c\u2500\u2500 ank\n\u2502       \u251c\u2500\u2500 ank-agent\n\u2502       \u2514\u2500\u2500 ank-server\n\u2514\u2500\u2500 req_tracing_report.html\n</code></pre> <p>The platform specific files are downloaded into a sub-folder <code>dist/&lt;os&gt;-&lt;platform&gt;/bin</code>. Reports and shared artifacts are placed into the <code>dist</code> folder directly.</p> <p>The scripts expect this folder structure to create final release artifacts.</p>"},{"location":"development/ci-cd-release/#adding-a-new-platform","title":"Adding a new Platform","text":"<p>If a new platform shall be supported the following steps must be done:</p> <ol> <li>If not already done, add a build job for the new platform in <code>.github/workflows/build.yml</code> and configure the upload of the artifacts, see CI/CD section.</li> <li>Configure the release workflow under <code>.github/workflows/release.yml</code> to download the new artifacts.    Under <code>jobs.release.steps</code> add a new step after the existing download steps and replace the parameters <code>&lt;os&gt;-&lt;platform&gt;</code> with the correct text (e.g. linux-amd64):</li> </ol> <pre><code> jobs:\n   ...\n   release:\n     steps:\n     ...\n     - name: Download artifacts for ankaios-&lt;os&gt;-&lt;platform&gt;-bin\n       uses: actions/download-artifact@v3.0.2\n       with:\n         name: ankaios-&lt;os&gt;-&lt;platform&gt;-bin\n         path: dist/&lt;os&gt;-&lt;platform&gt;/bin\n     ...\n</code></pre> <p>The name <code>ankaios-&lt;os&gt;-&lt;platform&gt;-bin</code> must match the used name in the upload artifact action defined inside the build workflow (<code>.github/workflows/build.yml</code>). 3. Inside <code>tools/create_release.sh</code> script add a new call to the script <code>tools/create_artifacts.sh</code> like the following:</p> <pre><code>...\n \"${SCRIPT_DIR}\"/create_artifacts.sh -p &lt;os&gt;-&lt;platform&gt;\n...\n</code></pre> <p>The <code>&lt;os&gt;-&lt;platform&gt;</code> string must match the name of the sub-folder inside the dist folder. The called script expects the pre-built binaries inside <code>&lt;os&gt;-&lt;platform&gt;/bin</code>.</p> <ol> <li>Configure the upload of the new release artifact in the release workflow inside <code>.github/workflows/release.yml</code>.    Inside the step that uploads the release artifacts add the new artifact(s) to the github upload command:</li> </ol> <pre><code>...\nrun: |\n  gh release upload ${{ github.ref_name }}\n   ...\n   &lt;os&gt;-&lt;platform&gt;/ankaios-&lt;os&gt;-&lt;platform&gt;.tar.gz \\\n   &lt;os&gt;-&lt;platform&gt;/ankaios-&lt;os&gt;-&lt;platform&gt;.tar.gz.sha512sum.txt\n   ...\n</code></pre> <ol> <li>Test and run the release workflow and check if the new artifact is uploaded correctly.</li> <li>Validate if the platform auto-detect mechanism of the installation script is supporting the new platform <code>tools/install.sh</code> and update the script if needed.</li> </ol>"},{"location":"development/ci-cd-release/#release-notes","title":"Release notes","text":"<p>The release notes are generated automatically if a release is created via the GitHub web frontend by clicking on the <code>Generate release notes</code> button.</p> <p>The procedure uses the filters for pull request labels configured inside <code>.github/release.yml</code>.</p>"},{"location":"development/ci-cd-release/#preparing-a-release","title":"Preparing a release","text":"<p>The following steps shall be done before the actual release build is triggered.</p> <ol> <li>Create an isssue containing tasks for getting the main branch ready:<ol> <li>Update the versions in the project packages (Cargo.toml files) to the new version.</li> <li>Execute tests on the supported targets.</li> <li>Make sure there are no security warnings of Github dependabot.</li> </ol> </li> <li>Finish all tasks inside the issue.</li> <li>Build the release according to the steps described here.</li> </ol>"},{"location":"development/ci-cd-release/#building-a-release","title":"Building a release","text":"<p>Before building the release, all preparation steps shall be finished before.</p> <p>The release shall be created directly via the GitHub web frontend.</p> <p>When creating a release a tag with the following naming convention must be provided: <code>vX.Y.Z</code> (e.g. v0.1.0).</p> <ol> <li>Go to the release section inside the repository and click on <code>Draft a new release</code>.</li> <li>Choose the tag to be created on publish.</li> <li>As release name enter the same tag.</li> <li>Click on the button <code>Generate release notes</code> to generate the release notes automatically based on the filter settings for pull requests inside <code>.github/release.yml</code> configuration. In case of unwanted pull requests are listed, label the pull requests correctly, delete the description field and generate the release notes again (The correction of the labels and the regeneration of the release notes can also be done after the release build.).</li> <li>Make sure that the check box <code>Set as the latest release</code> is enabled. This setting is important otherwise the provided link for the installation script in chapter installation is still pointing to the previous release marked as latest.</li> <li>Click on <code>Publish release</code>.</li> <li>Go to GitHub Actions section and wait until the release workflow has finished.</li> <li>If the release build finished successfully, go to the release section again and validate that all required artifacts are uploaded to the new release.</li> <li>If the release workflow fails, delete the release and the tag manually via the GitHub web frontend. Next, check the logs of the release workflow and fix the issues. Repeat the steps starting at step 1.</li> </ol> <p>Note</p> <p>There is a GitHub Action available to automatically rollback the created release and tag. This action is not used to have a better control over the cleanup procedure before a next release build is triggered. For instance, without auto-rollback a manually entered release description is still available after a failing release build.</p>"},{"location":"development/ci-cd/","title":"CI/CD","text":"<p>As CI/CD environment GitHub Actions is used. Merge verifications in case of opening a pull request and release builds are fully covered into GitHub Action workflows. For information about release builds, see CI/CD - Release section.</p>"},{"location":"development/ci-cd/#merge-verification","title":"Merge verification","text":"<p>When a pull request is opened, the following pipeline jobs run:</p> <ul> <li>Linux-amd64 release build + tests in debug mode</li> <li>Linux-amd64 coverage test report</li> <li>Linux-arm64 release build (cross platform build)</li> <li>Requirements tracing</li> </ul> <p>After a pull request was merged into the main branch, the jobs listed above are executed again to validate stable branch behavior.</p> <p>The steps for the build workflow are defined inside <code>.github/workflows/build.yml</code>.</p> <p>The produced artifacts of the build workflow are uploaded and can be downloaded from GitHub for debugging or testing purposes.</p>"},{"location":"development/ci-cd/#adding-a-new-merge-verification-job","title":"Adding a new merge verification job","text":"<p>To add a new merge verification job adjust the workflow defined inside <code>.github/workflows/build.yml</code>.</p> <p>Select a GitHub runner image matching your purposes or in case of adding a cross-build first make sure that the build works locally within the dev container.</p> <ol> <li>Add a new build job under the <code>jobs</code> jobs section and define a job name.</li> <li>Add the necessary steps to the job to build the artifact(s).</li> <li>Append a use clause to the build steps to upload the artifacts to GitHub. If a new platform build is added name the artifact according to the naming convention <code>ankaios-&lt;os&gt;-&lt;platform&gt;-bin</code> (e.g. ankaios-linux-amd64-bin) otherwise define a custom name. If the artifact is needed inside a release the artifact is referenced with this name inside the release workflow.</li> </ol> <pre><code> ...\n  - uses: actions/upload-artifact@v3.1.2\n    with:\n      name: ankaios-&lt;os&gt;-&lt;platform&gt;-bin\n      path: dist/\n ...\n</code></pre> <p>Note</p> <p>GitHub Actions only runs workflow definitions from main (default) branch. That means when a workflow has been changed and a PR has been created for that, the change will not become effective before the PR is merged in main branch. For local testing the act tool can be used.</p>"},{"location":"development/ci-cd/#adding-a-new-github-action","title":"Adding a new GitHub action","text":"<p>When introducing a new GitHub action, do not use a generic major version tag (e.g. <code>vX</code>). Specify a specific release tag (e.g. <code>vX.Y.Z</code>) instead. Using the generic tag might lead to an unstable CI/CD environment, whenever the authors of the GitHub action update the generic tag to point to a newer version that contains bugs or incompatibilities with the Ankaios project.</p> <p>Example:</p> <p>Bad:</p> <pre><code>...\n  - uses: actions/checkout@v4\n...\n</code></pre> <p>Good:</p> <pre><code>...\n  - uses: actions/checkout@v4.1.1\n...\n</code></pre>"},{"location":"development/ci-cd/#adding-github-action-jobs","title":"Adding GitHub action jobs","text":"<p>When creating a new job inside a workflow, specify a job name for each job.</p> <p>Example:</p> <pre><code>...\n\njobs:\n  test_and_build_linux_amd64:\n    name: Test and Build Linux amd64\n...\n</code></pre> <p>Note</p> <p>Beside being a best practice, giving a job a name is needed to reference it from the self-service repository in order to configure the job as a required status check.</p>"},{"location":"development/documentation-guidelines/","title":"Documentation guidelines","text":"<p>These guidelines apply to all documentation which is created in the Ankaios project like this website, software design documents or README files. The aim is to support the creators of documents by enforcing a common look and feel.</p>"},{"location":"development/documentation-guidelines/#capitalization","title":"Capitalization","text":"<p>As 'Ankaios' is a proper noun it shall be written with a capital 'A'. Other words which are not proper nouns shall be in lower case when they are not the first word in a sentence.</p> <p>Examples:</p> Correct Incorrect Ankaios ankaios Ankaios server Ankaios-Server, Ankaios-server, Ankaios Server Ankaios agent Ankaios-Agent, Ankaios-agent, Ankaios Agent workload Workload control interface Control Interface <p>The same rule also applies to headlines, i.e. only the first word of a headline is in upper case.</p>"},{"location":"development/extending-dev-container/","title":"Extending the dev container","text":"<p>The dev container is relatively large. Thus, we have split a base container which is available from <code>ghcr.io/eclipse-ankaios/devcontainer</code>.</p> <p>If there is a need to include additional items in the dev container, please note that it is split into two parts due to its size:</p> <ul> <li> <p>a base container which, in case of a change, needs to be build manually from .devcontainer/Dockerfile.base by running the following outside of the dev container:</p> <pre><code># Prepare the build with buildx. Depending on you environment\n# the following steps might be necessary:\ndocker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n# Create and use a new builder. This needs top be called only once:\ndocker buildx create --name mybuilder --driver docker-container --bootstrap\ndocker buildx use mybuilder\n\n# Now build new base image for the dev container\ncd .devcontainer\ndocker buildx build -t ghcr.io/eclipse-ankaios/devcontainer-base:&lt;version&gt; --platform linux/amd64,linux/arm64 -f Dockerfile.base .\n</code></pre> <p>In order to push the base image append <code>--push</code> to the previous command.</p> <p>Note: If you wish to locally test the base image in VSCode before proceeding, utilize the default builder and exclusively build for the default platform like</p> <pre><code>docker buildx use default\ndocker buildx build -t ghcr.io/eclipse-ankaios/devcontainer-base:&lt;version&gt; -f Dockerfile.base --load .\n</code></pre> </li> <li> <p>a docker container which derives from the base image mentioned above is specified in <code>.devcontainer/Dockerfile</code> (so don't forget to reference your new version there once you build one).</p> </li> </ul> <p>If you want to add some additional tools, you can initially do it in <code>.devcontainer/Dockerfile</code>, but later on they need to be pulled in the base image at some point in order to speed up the initial dev container build.</p>"},{"location":"development/requirement-tracing/","title":"Requirement tracing","text":""},{"location":"development/requirement-tracing/#introduction","title":"Introduction","text":"<p>The Eclipse Ankaios project provides requirement tracing using the OpenFastTrace requirement tracing suite. The dev container already includes the required tooling. To generate a requirement tracing report call:</p> <pre><code>tools/generate_oft_html_report.sh\n</code></pre> <p>Afterwards the HTML report is available under <code>build/req/req_tracing_report.html</code> and shows the current coverage state.</p> <p>For details on the OpenFastTrace tool, please consult OFT's user documentation or execute <code>oft help</code>.</p>"},{"location":"development/requirement-tracing/#adding-requirements","title":"Adding requirements","text":"<p>Eclipse Ankaios traces requirements between</p> <ul> <li>Design (<code>**/doc/README.md</code>)</li> <li>Implementations (<code>**/src/**</code>)</li> <li>Tests (<code>**/src/**</code>, <code>tests/**</code>)</li> </ul> <p>Thus, for new features:</p> <ul> <li>New requirements need to be added in the design or existing requirements need to be modified (type <code>swdd</code>)</li> <li>Mark the parts in the source code that actually implement the design requirement using the type <code>impl</code>, e.g., <code>// [impl-&gt;swdd~this-is-a-requirement~1]</code></li> <li>Mark the tests that check the implementation of the design with one of the types <code>utest</code>, <code>itest</code> or <code>stest</code> depending on the type of the test, e.g., <code>// [utest-&gt;swdd~this-is-a-requirement~1]</code> for a unit test</li> </ul>"},{"location":"development/run-unit-tests/","title":"Unit tests with cargo-nextest","text":"<p>We use test runner cargo-nextest because of the following reasons:</p> <ol> <li>It runs tests faster than <code>cargo test</code>.</li> <li>It presents the test results concisely so you can see which tests passed and failed at a glance.</li> <li>If debug logs are activated, it prints the debug logs only when a test has failed, so that it is clear the debug logs belong that failed test.</li> </ol>"},{"location":"development/run-unit-tests/#run-unit-tests","title":"Run unit tests","text":"<p>If you want to run all unit tests without traces, call in the root of the project:</p> <pre><code>cargo nextest run\n</code></pre> <p>Some unit tests can print trace logs. If you want to see them, you have to set the <code>RUST_LOG</code> environment variable before running unit tests.</p> <pre><code>RUST_LOG=debug cargo nextest run\n</code></pre> <p>Cargo-nextest also allows to run only a subset of unit tests. You have to set the \"filter string\" in the command:</p> <pre><code>cargo nextest run &lt;filter string&gt;\n</code></pre> <p>Where the <code>filter string</code> is part of unit test name. For example we have a unit test with the name:</p> <pre><code>test podman::workload::container_create_success\n</code></pre> <p>If you want to call only this test, you can call:</p> <pre><code>cargo nextest run workload::container_create_success\n</code></pre> <p>If you want to call all tests in <code>workload.rs</code>, you have to call:</p> <pre><code>cargo nextest run podman::workload\n</code></pre> <p>You can also call only tests in <code>workload.rs</code>, which have a name starting with <code>container</code>:</p> <pre><code>cargo nextest run podman::workload::container\n</code></pre>"},{"location":"development/rust-coding-guidelines/","title":"Rust coding guidelines","text":"<p>When engaging in collaborative software projects, it is crucial to ensure that the code is well-organized and comprehensible. This facilitates ease of maintenance and allows for seamless extension of the project. To accomplish this objective, it is essential to establish shared guidelines that the entire development team adheres to.</p> <p>The goal is to get a harmonized code-base which appears to come from the same hands. This simplifies reading and understanding the intention of the code and helps maintaining the development speed.</p> <p>The following chapters describe rules and concepts to fit clean code expectations.</p>"},{"location":"development/rust-coding-guidelines/#clean-code","title":"Clean code","text":"<p>We like our code clean and thus use the \"Clean Code\" rules from \"uncle Bob\". A short summary can be found here.</p> <p>As rust could get a bit messy, feel free to add some additional code comments to blocks that cannot be made readable using the clean code rules.</p>"},{"location":"development/rust-coding-guidelines/#naming-conventions","title":"Naming conventions","text":"<p>We follow the standard Rust naming conventions.</p> <p>Names of components, classes , functions, etc. in code should also follow the prescriptions in SW design. Before thinking of new names, please make sure that we have not named the beast already.</p> <p>Names of unit tests within a file shall be hierarchical. Tests which belong together shall have the same prefix. For example the file <code>workload.rs</code> contains following tests:</p> <ul> <li><code>container_create_success</code></li> <li><code>container_create_failed</code></li> <li><code>container_start_success</code></li> <li><code>container_start_failure_no_id</code></li> </ul> <p>So if you want to call tests which work with container, you can write</p> <pre><code>cargo nextest run container\n</code></pre> <p>If you want to call tests of the \"container create\" function, you can call:</p> <pre><code>cargo nextest run container_create\n</code></pre> <p>More information about calling unit tests is in The Rust Programming Language.</p>"},{"location":"development/rust-coding-guidelines/#logging-conventions","title":"Logging conventions","text":"<p>The following chapters describe rules for creating log messages.</p>"},{"location":"development/rust-coding-guidelines/#log-format-of-internal-objects","title":"Log format of internal objects","text":"<p>When writing log messages that reference internal objects, the objects shall be surrounded in single quotes, e.g.:</p> <pre><code>log::info!(\"This is about object '{}'.\", object.name)\n</code></pre> <p>This helps differentiate static from dynamic data in the log message.</p>"},{"location":"development/rust-coding-guidelines/#log-format-of-multiline-log-messages","title":"Log format of multiline log messages","text":"<p>Multi line log messages shall be created with the <code>concat!</code> macro, e.g.:</p> <pre><code>log::debug!(concat!(\n    \"First line of a log message that lists something:\\n\",\n    \"   flowers are: '{}'\\n\",\n    \"   weather is: {}\")\n    color, current_weather);\n</code></pre> <p>This ensures that the log messages are formatted correctly and simplifies writing the message.</p>"},{"location":"development/rust-coding-guidelines/#choose-a-suitable-log-severity","title":"Choose a suitable log severity","text":"Severity Use Case Trace A log that is useful for diagnostic purposes and/or more granular than severity debug. Debug A log that is useful for developers meant for debugging purposes or hit very often. Info A log communicating important information like important states of an application suitable for any kind of user and that does not pollute the output. Warn A log communicating wrong preconditions or occurrences of something unexpected but do not lead to a panic of the application. Error A log communicating failures and consequences causing a potential panic of the application."},{"location":"development/rust-coding-guidelines/#unit-test-convenience-rules","title":"Unit test convenience rules","text":"<p>The following chapter describes important rules about how to write unit tests.</p>"},{"location":"development/rust-coding-guidelines/#test-mockobject-generation","title":"Test mock/object generation","text":"<p>When writing tests, one of the most tedious task is to setup the environment and create the necessary objects and/or mocks to be able to test the desired functionality. Following the DRY principle and trying to save some effort, we shall always place the code that generates a test or mock object in the same module/file where the mock of the object is defined.</p> <p>For example, when you would like to generate and reuse a mock for the <code>Directory</code> structure located in the <code>agent/src/control_interface/directory.rs</code> file, you shall</p> <ul> <li>write a public setup function:</li> </ul> <pre><code>pub fn generate_test_directory_mock() -&gt; __mock_MockDirectory::__new::Context;\n</code></pre> <p>The <code>&lt;datatype_name&gt;</code> in <code>__mock_Mock&lt;datatype_name&gt;::__new::Context</code> must be replaced with the name of the type the mock is created for.</p> <ul> <li>place the function in the test part of the file (after the test banner if you use one)</li> <li>place a <code>#[cfg(test)]</code> (or <code>#[cfg(feature = \"test_utils\")]</code> in case of a library) before the function to restrict its compilation to test only</li> <li>use this function in all places where you need</li> <li>If you need some variation in the output or the behavior of the function, you can, of course, make it parametrized.</li> </ul> <p>All object/mock generation functions shall start with <code>generate_test_</code>.</p>"},{"location":"development/rust-coding-guidelines/#advanced-rules","title":"Advanced rules","text":""},{"location":"development/rust-coding-guidelines/#don-t-reinvent-the-wheel","title":"Don' t reinvent the wheel","text":"<p>Bad:</p> <pre><code>let numbers = vec![1, 2, 3, 4, 5, 6, 7, 8];\n\nlet mut filtered_numbers = Vec::new();\n// filter numbers smaller then 3\nfor number in numbers {\n    if number &lt; 3 {\n        filtered_numbers.push(number);\n    }\n}\n</code></pre> <p>Good:</p> <p>Prefer standard library algorithms over own implementations to avoid error prone code.</p> <pre><code>let numbers = vec![1, 2, 3, 4, 5, 6, 7, 8];\nlet filtered_numbers: Vec&lt;i32&gt; = numbers.into_iter().filter(|x| x &lt; &amp;3).collect();\n</code></pre>"},{"location":"development/rust-coding-guidelines/#prefer-error-propagation","title":"Prefer error propagation","text":"<p>Bad:</p> <p>A lot of conditionals for opening and reading a file.</p> <pre><code>use std::fs::File;\nuse std::io;\nuse std::io::Read;\n\nfn read_from_file(filepath: &amp;str) -&gt; Result&lt;String, io::Error&gt; {\n    let file_handle = File::open(filepath);\n    let mut file_handle = match file_handle {\n        Ok(file) =&gt; file,\n        Err(e) =&gt; return Err(e),\n    };\n\n    let mut buffer = String::new();\n\n    match file_handle.read_to_string(&amp;mut buffer) {\n        Ok(_) =&gt; Ok(buffer),\n        Err(e) =&gt; Err(e)\n    }\n}\n</code></pre> <p>Good:</p> <p>Prefer error propagation over exhaustive match and conditionals.</p> <p>Error propagation shortens and cleans up the code path by replacing complex and exhaustive conditionals with the <code>?</code> operator without loosing the failure checks.</p> <p>The refactored variant populates the error and success case the same way to the caller like in the bad example above, but is more readable:</p> <pre><code>fn read_from_file(filepath: &amp;str) -&gt; Result&lt;String, io::Error&gt; {\n    let mut buffer = String::new();\n    File::open(filepath)?.read_to_string(&amp;mut buffer)?;\n    Ok(buffer)\n}\n</code></pre> <p>In case of mismatching error types, provide a custom From-Trait implementation to convert between error types to keep the benefits of using the <code>?</code> operator. But keep in mind that error conversion shall be used wisely (e.g. for abstracting third party library error types or if there is a benefit to introduce a common and reusable error type). The code base shall not be spammed with From-Trait implementations to replace each single match or conditional.</p> <p>Error propagation shall also be preferred when converting between <code>Result&lt;T,E&gt;</code> and <code>Option&lt;T&gt;</code>.</p> <p>Bad:</p> <pre><code>fn string_to_percentage(string: &amp;str) -&gt; Option&lt;f32&gt; {\n    // more error handling\n    match string.parse::&lt;f32&gt;() {\n        Ok(value) =&gt; Some(value * 100.),\n        _ =&gt; None,\n    }\n}\n</code></pre> <p>Good:</p> <pre><code>fn string_to_percentage(string: &amp;str) -&gt; Option&lt;f32&gt; {\n    // more error handling\n    let value = string.parse::&lt;f32&gt;().ok()?; // returns None on parsing error\n    Some(value * 100.)\n}\n</code></pre>"},{"location":"development/rust-coding-guidelines/#avoid-unwrap-and-expect","title":"Avoid unwrap and expect","text":"<p><code>Unwrap</code> or <code>expect</code> return the value in success case or call the <code>panic!</code> macro if the operation has failed. Applications that are often terminated directly in case of errors are considered as unprofessional and not useful.</p> <p>Bad:</p> <pre><code>let value = division(10, 0).unwrap(); // panics, because of a simple division!!!\n</code></pre> <p>Good:</p> <p>Replace <code>unwrap</code> or <code>expect</code> with a conditional check, e.g. match expression:</p> <pre><code>let value = division(10, 0); // division 10 / 0 not allowed, returns Err\n\n// conditional check before accessing the value\nmatch value {\n    Ok(value) =&gt; println!(\"{value}\"),\n    Err(e) =&gt; eprintln!(\"{e}\")\n}\n</code></pre> <p>or with if-let condition when match is awkward:</p> <pre><code>// access value only on success\nif let Ok(value) = division(10, 0) {\n    println!(\"{value}\")\n}\n</code></pre> <p>or if possible continue with some default value in case of an error:</p> <pre><code>let result = division(10, 0).unwrap_or(0.);\n</code></pre> <p>Exceptions:</p> <p>In some cases terminating a program might be necessary. To make a good decision when to panic a program or not, the official rust book might help: To panic! or Not to panic!</p> <p>When writing unit tests using <code>unwrap</code> helps to keep tests short and to concentrate on the <code>assert!</code> statements:</p> <p>Bad:</p> <pre><code>let container: Option&lt;HashMap&lt;i32, String&gt;&gt; = operation_under_test();\nmatch container {\n    Some(container) =&gt; {\n        match container.get(&amp;0) {\n            Some(value_of_0) =&gt; assert_eq!(value_of_0, &amp;\"hello world\".to_string()),\n            _ =&gt; { panic!(\"Test xy failed, no entry.\") }\n        }\n    },\n    _ =&gt; { panic!(\"Test xy failed, no container.\") }\n}\n</code></pre> <p>Good:</p> <p>Prefer direct <code>unwrap</code> calls over <code>assert!</code> statements nested in complex conditional clauses. It is shorter and the <code>assert!</code> statement is directly eye-catching.</p> <pre><code>let container: Option&lt;HashMap&lt;i32, String&gt;&gt; = operation_under_test();\nlet value_of_0 = container.unwrap().remove(&amp;0).unwrap(); // the test is failing on error\n\nassert_eq!(value_of_0, \"hello world\".to_string());\n</code></pre>"},{"location":"development/rust-coding-guidelines/#prefer-while-let-over-match-in-loops","title":"Prefer while-let over match in loops","text":"<p>Use the shorter and cleaner while-let expression to eliminate exhaustive match sequences in loops:</p> <p>Bad:</p> <pre><code>loop {\n    match generate() {\n        Some(value) =&gt; println!(\"{value}\"),\n        _ =&gt; { break; },\n    }\n}\n</code></pre> <p>Good:</p> <pre><code>// if success use the value else break\n// ...or while let Ok(value) in case of Result&lt;T,E&gt; instead of Option&lt;T&gt;\nwhile let Some(value) = generate() {\n    println!(\"{value}\")\n}\n</code></pre>"},{"location":"development/rust-coding-guidelines/#prefer-lazily-evaluated-functional-chaining","title":"Prefer lazily evaluated functional chaining","text":"<p>Bad:</p> <p>Eagerly evaluated functions are always evaluated regardless of the success or error case. If the alternative is not taken potentially costly operations are performed unnecessarily.</p> <pre><code>let value = division(2., 10.);\nlet result = value.and(to_percentage(value)); // eagerly evaluated\n\nlet value = division(2., 10.);\nlet result = value.or(provide_complex_alternative()); // eagerly evaluated\n\nlet value = division(2., 10.);\nlet result = value.unwrap_or(generate_complex_default()); // eagerly evaluated\n</code></pre> <p>Good:</p> <p>Lazily evaluated functions are only evaluated if the case actually occurs and are preferred if the alternatives provide costly operations.</p> <pre><code>let result = division(2., 10.).and_then(to_percentage); // lazily evaluated\n\nlet result = division(2., 10.).or_else(provide_complex_alternative); // lazily evaluated\n\nlet result = division(2., 10.).unwrap_or_else(generate_complex_default); // lazily evaluated\n</code></pre>"},{"location":"development/rust-coding-guidelines/#avoid-exhaustive-nested-code","title":"Avoid exhaustive nested code","text":"<p>Bad:</p> <p>The code is hard to read and the interesting code path is not an eye-catcher.</p> <pre><code>fn list_books(&amp;self) -&gt; Option&lt;Vec&lt;String&gt;&gt; {\n    if self.wifi {\n        if self.login {\n            if self.admin {\n                return Some(get_list_of_books());\n            } else {\n                eprintln!(\"Expected login as admin.\");\n            }\n        } else {\n            eprintln!(\"Expected login.\");\n        }\n    } else {\n        eprintln!(\"Expected connection.\");\n    }\n    None\n}\n</code></pre> <p>Good:</p> <p>Nest code only into 1 or 2 levels. Use early-exit pattern to reduce the nest level and to separate error handling code from code doing the actual logic.</p> <pre><code>fn list_books(&amp;self) -&gt; Option&lt;Vec&lt;String&gt;&gt; {\n    if !self.wifi {\n        eprintln!(\"Expected connection.\");\n        return None;\n    }\n\n    if !self.login {\n        eprintln!(\"Expected login.\");\n        return None;\n    }\n\n    if !self.admin {\n        eprintln!(\"Expected login as admin.\");\n        return None;\n    }\n\n    // interesting part\n    Some(get_list_of_books())\n}\n</code></pre> <p>As an alternative, when dealing with <code>Option&lt;T&gt;</code> or <code>Result&lt;T,E&gt;</code> use Rust's powerful combinators to keep the code readable.</p>"},{"location":"development/rust-coding-guidelines/#follow-common-rust-principles-and-idioms","title":"Follow common Rust principles and idioms","text":"<p>Understanding and practicing important Rust idioms help to write code in an idiomatic way, meaning resolving a task by following the conventions of a given language. Writing idiomatic Rust code ensures a clean and consistent code base. Thus, please follow the guidelines of Idiomatic Rust.</p>"},{"location":"development/rust-coding-guidelines/#avoid-common-anti-patterns","title":"Avoid common anti-patterns","text":"<p>There are a lot of Rust anti-patterns that shall not be used in general. To get more details about anti-patterns, see here.</p>"},{"location":"development/rust-coding-guidelines/#dont-make-sync-code-async","title":"Don't make sync code async","text":"<p>Async code is mainly used for I/O intensive, network or background tasks (Databases, Servers) to allow executing such tasks in a non-blocking way, so that waiting times can be used reasonably for executing other operations. However operations that do not fit to async use cases and are called synchronously shall not be made async because there is no real benefit. Async code is more difficult to understand than synchronous code.</p> <p>Bad:</p> <p>No need for making those operations async, because they are exclusively called synchronously. It is just more syntax and the code raises more questions about the intent to the reader.</p> <pre><code>let result1 = operation1().await;\nlet result2 = operation2().await;\nlet result3 = operation3().await;\n</code></pre> <p>Good:</p> <p>Keep it synchronous and thus simple.</p> <pre><code>let result1 = operation1();\nlet result2 = operation2();\nlet result3 = operation3();\n</code></pre>"},{"location":"development/rust-coding-guidelines/#dont-mix-sync-and-async-code-without-proper-consideration","title":"Don\u2019t mix sync and async code without proper consideration","text":"<p>Mixing sync and async code can lead to a number of problems, including performance issues, deadlocks, and race conditions. Avoid mixing async with sync code unless there is a good reason to do so.</p>"},{"location":"development/rust-coding-guidelines/#further-readings","title":"Further Readings","text":"<ul> <li>https://rustc-dev-guide.rust-lang.org/conventions.html</li> <li>https://www.kernel.org/doc/html/next/rust/coding-guidelines.html</li> <li>https://rust-lang.github.io/api-guidelines/about.html</li> </ul>"},{"location":"development/self-service/","title":"Eclipse self-service","text":"<p>The Eclipse Foundation offers self-service of GitHub resources. We are using this self-service to customize Github settings, for example to change branch protection rules or other important settings of the Ankaios project. The current GitHub configuration is hosted as code inside a separate repository called .eclipsefdn.</p> <p>The settings are in jsonnet format and can be modified by contributors.</p> <p>A detailed overview of the self-service please have a look into the self-service handbook.</p>"},{"location":"development/self-service/#process-of-changing-the-settings","title":"Process of changing the settings","text":"<p>If a configuration needs to be changed the process is the following:</p> <ol> <li>Fork the .eclipsefdn repository.</li> <li>Do the configuration changes (Use the Eclipse playground for trying out the available settings).</li> <li>Open a PR pointing from your fork's branch to the .eclipsefdn repository.</li> <li>Make sure that a review is requested from: Ankaios project committer, eclipsefdn-releng, eclipsefdn-security.</li> <li>After the changes were approved by the reviewers, a member of Eclipse Foundation IT staff will merge the PR and applies the new settings by using the otterdog cli.</li> </ol>"},{"location":"development/system-tests/","title":"System tests","text":""},{"location":"development/system-tests/#general-overview","title":"General overview","text":"<p>System tests are a critical phase of software testing, aimed at evaluating the entire software system as a whole to ensure that it meets its specified requirements and functions correctly in its intended environment. These tests are conducted after unit and integration testing and serve as a comprehensive validation of the software's readiness for deployment.</p> <p>Here are key aspects of system tests:</p> <ol> <li> <p>End-to-End Evaluation: System tests assess the software's performance, functionality, and reliability in a real-world scenario, simulating the complete user journey. They cover all aspects of the system, from the user interface to the backend processes.</p> </li> <li> <p>Functional and Non-Functional Testing: These tests not only verify that the software's features work as intended (functional testing) but also assess non-functional attributes like performance, scalability, security, and usability.</p> </li> <li> <p>Scenario-Based Testing: Test scenarios are designed to replicate various user interactions, use cases, and business workflows. This includes testing different paths, inputs, and error conditions to ensure the system handles them correctly.</p> </li> <li> <p>Interoperability Testing: In cases where the software interacts with external systems or components, system tests evaluate its compatibility and ability to communicate effectively with these external entities.</p> </li> <li> <p>Data Integrity and Security: Ensuring the protection of sensitive data and the integrity of information is a critical part of system testing. This includes checking for vulnerabilities and ensuring compliance with security standards.</p> </li> <li> <p>Performance Testing: Assessing the system's response times, resource utilization, and scalability under various load conditions to ensure it can handle expected levels of usage.</p> </li> <li> <p>Regression Testing: System tests often include regression testing to ensure that new features or changes do not introduce new defects or disrupt existing functionality.</p> </li> </ol>"},{"location":"development/system-tests/#robot-test-framework-for-system-tests","title":"Robot test framework for system tests","text":"<p>The Robot test framework, often referred to as just \"Robot Framework,\" is a popular open-source test automation framework used for automating test cases in various software applications. It is designed to be easy to use, highly readable, and adaptable for both beginners and experienced testers. It employs a keyword-driven approach, which means that test cases are written using a combination of keywords that represent actions, objects, and verifications. These keywords can be custom-defined by using Python programming language or come from libraries specific to the application under test. One of the standout features of Robot Framework is its human-readable syntax. Test cases are written in plain text composed with defined keywords, making it accessible to non-programmers and allowing stakeholders to understand and contribute to test case creation. Because of the ability to create custom keywords, a pool of domain specific and generic keywords could be defined to form an Ankaios project specific language for writing test cases.This makes it possible to directly use the test specifications written in natural language or the same wording of it to write automated test cases. This is the main reason why we use this test framework for system tests in Ankaios.</p>"},{"location":"development/system-tests/#system-tests-structure","title":"System tests structure","text":"<pre><code>ankaios                              # Ankaios root\n  |--tests                           # Location for system tests and their resources\n  |  |--resources                    # Location for test resources\n  |  |  |--configs                   # Location for test case specific start-up configuration files\n  |  |  |  |--default.yaml           # A start-up configuration file\n  |  |  |  |--... &lt;----------------  # Add more configuration files here!\n  |  |  |\n  |  |  |--ankaios_library.py        # Ankaios keywords implementations\n  |  |  |--ankaios.resource          # Ankaios keywords\n  |  |  |--variables.resource        # Ankaios variables\n  |  |  |--... &lt;-------------------  # Add more keywords and keywords implementation resources here!\n  |  |\n  |  |--stests                       # Location for system tests\n  |  |  |--workloads                 # Location for tests with specific test subject focus e.g. \"workloads\" for tests related \"workloads\"\n  |  |  |  |--list_workloads.robot   # A test suite testing \"list workloads\"\n  |  |  |  |--... &lt;----------------  # Add more tests related to \"workloads\" here!\n  |  |  |... &lt;---------------------  # Add test subject focus here!\n</code></pre>"},{"location":"development/system-tests/#system-test-creation","title":"System test creation","text":""},{"location":"development/system-tests/#a-generic-ankaios-system-test-structure","title":"A generic Ankaios system test structure","text":"<p>The most common approach to create a robot test is using the space separated format where pieces of the data, such as keywords and their arguments, are separated from each others with two or more spaces. A basic Ankaios system test consists of the following sections:</p> <pre><code># ./tests/stests/workloads/my_workload_stest.robot\n\n*** Settings ***\nDocumentation    Add test suit documentation here.      # Test suite documentation\nResource     ../../resources/ankaios.resource           # Ankaios specific keywords that forms the Ankaios domain language\nResource    ../../resources/variables.resource          # Ankaios variables e.g. CONFIGS_DIR\n\n*** Test Cases ***\n[Setup]        Setup Ankaios\n# ADD YOUR SYSTEM TEST HERE!\n[Teardown]    Clean up Ankaios\n</code></pre> <p>For more best practices about writing tests with Robot framework see here.</p>"},{"location":"development/system-tests/#behavior-driven-system-test","title":"Behavior-driven system test","text":"<p>Behavior-driven tests (BDT) use natural language specifications to describe expected system behavior, fostering collaboration between teams and facilitating both manual and automated testing. It's particularly valuable for user-centric and acceptance testing, ensuring that software aligns with user expectations. The Robot test framework supports BDT, and this approach shall be preferred for writing system tests in Ankaios the project.</p> <p>Generic structure of BDT:</p> <pre><code>*** Test Cases ***\n[Setup]        Setup Ankaios\nGiven  &lt;preconditions&gt;\nWhen   &lt;actions&gt;\nThen   &lt;asserts&gt;\n[Teardown]    Clean up Ankaios\n</code></pre> <p>Example: System test testing listing of workloads.</p> <pre><code>*** Settings ***\nDocumentation    Tests to verify that ank cli lists workloads correctly.\nResource     ../../resources/ankaios.resource\nResource    ../../resources/variables.resource\n\n*** Test Cases ***\nTest Ankaios CLI get workloads\n    [Setup]        Setup Ankaios\n    # Preconditions\n    Given Ankaios server is started with \"ank-server --startup-config ${CONFIGS_DIR}/default.yaml\"\n    And Ankaios agent is started with \"ank-agent --name agent_B\"\n    And all workloads of agent \"agent_B\" have an initial execution state\n    And Ankaios agent is started with \"ank-agent --name agent_A\"\n    And all workloads of agent \"agent_A\" have an initial execution state\n    # Actions\n    When user triggers \"ank get workloads\"\n    # Asserts\n    Then the workload \"nginx\" shall have the execution state \"Running\" on agent \"agent_A\"\n    And the workload \"hello1\" shall have the execution state \"Removed\" from agent \"agent_B\"\n    And the workload \"hello2\" shall have the execution state \"Succeeded\" on agent \"agent_B\"\n    And the workload \"hello3\" shall have the execution state \"Succeeded\" on agent \"agent_B\"\n    [Teardown]    Clean up Ankaios\n</code></pre>"},{"location":"development/system-tests/#system-test-execution","title":"System test execution","text":"<p>Warning</p> <p>The system tests will delete all Podman containers, pods and volume. We recomment to only execute the system tests in the dev container.</p> <p>A shell script is provided for the easy execution of the system tests. The script does the following:</p> <ol> <li>It checks if the required Ankaios executables (<code>ank</code>, <code>ank-server</code> and <code>ank-agent</code>) are available at specified path.</li> <li>It prints out the version number executables.</li> <li>It starts all the tests under specified folder or a specific robot test file.</li> <li>It stores the test result in the folder <code>{Ankaios root folder}/target/robot_tests_result</code>.</li> </ol>"},{"location":"development/system-tests/#run-in-dev-container","title":"Run in dev container","text":"<p>Generic syntax:</p> <pre><code>/workspaces/ankaios$ [ANK_BIN_DIR=path_to_ankaios_executables] tools/run_robot_tests &lt;options&gt; &lt;directory or robot file&gt;\n</code></pre> <p>If ANK_BIN_DIR is not provided the script looks in the path <code>{Ankaios root folder}/target/x86_64-unknown-linux-musl/debug</code> for the Ankaios executables. The supported options are the same as of <code>robot</code> cli, so for more detailed description about it see here.</p> <p>Note: In order to be able to start <code>podman</code> runtime in the dev container properly, the dev container needs to be run in <code>privilege</code> mode.</p>"},{"location":"development/system-tests/#example-run-all-tests-under-the-folder-tests","title":"Example: Run all tests under the folder tests","text":"<pre><code>/workspaces/ankaios$ tools/run_robot_tests.sh tests\n</code></pre> <p>Example output:</p> <pre><code>Use default executable directory: /workspaces/ankaios/tools/../target/x86_64-unknown-linux-musl/debug\nFound ank 0.1.0\nFound ank-server 0.1.0\nFound ank-agent 0.1.0\n==============================================================================\nTests\n==============================================================================\nTests.Stests\n==============================================================================\nTests.Stests.Workloads\n==============================================================================\nTests.Stests.Workloads.List Workloads :: List workloads test cases.\n==============================================================================\nTest Ankaios CLI get workloads                                        | PASS |\n------------------------------------------------------------------------------\nTests.Stests.Workloads.List Workloads :: List workloads test cases.   | PASS |\n1 test, 1 passed, 0 failed\n==============================================================================\nTests.Stests.Workloads.Update Workload :: Update workload test cases.\n==============================================================================\nTest Ankaios CLI update workload                                      | PASS |\n------------------------------------------------------------------------------\nTests.Stests.Workloads.Update Workload :: Update workload test cases. | PASS |\n1 test, 1 passed, 0 failed\n==============================================================================\nTests.Stests.Workloads                                                | PASS |\n2 tests, 2 passed, 0 failed\n==============================================================================\nTests.Stests                                                          | PASS |\n2 tests, 2 passed, 0 failed\n==============================================================================\nTests                                                                 | PASS |\n2 tests, 2 passed, 0 failed\n==============================================================================\nOutput:  /workspaces/ankaios/target/robot_tests_result/output.xml\nLog:     /workspaces/ankaios/target/robot_tests_result/log.html\nReport:  /workspaces/ankaios/target/robot_tests_result/report.html\n</code></pre>"},{"location":"development/system-tests/#example-run-a-single-test-file","title":"Example: Run a single test file","text":"<pre><code>/workspaces/ankaios$ tools/run_robot_tests.sh tests/stests/workloads/list_workloads.robot\n</code></pre> <p>Example output:</p> <pre><code>Use default executable directory: /workspaces/ankaios/tools/../target/x86_64-unknown-linux-musl/debug\nFound ank 0.1.0\nFound ank-server 0.1.0\nFound ank-agent 0.1.0\n==============================================================================\nList Workloads :: List workloads test cases.\n==============================================================================\nTest Ankaios CLI get workloads                                        | PASS |\n------------------------------------------------------------------------------\nList Workloads :: List workloads test cases.                          | PASS |\n1 test, 1 passed, 0 failed\n==============================================================================\nOutput:  /workspaces/ankaios/target/robot_tests_result/output.xml\nLog:     /workspaces/ankaios/target/robot_tests_result/log.html\nReport:  /workspaces/ankaios/target/robot_tests_result/report.html\n</code></pre>"},{"location":"development/system-tests/#integration-in-github-workflows","title":"Integration in GitHub workflows","text":"<p>The execution of the system tests is integrated in the GitHub workflow build step and will be triggered on each commit on a pull request.</p>"},{"location":"development/test-coverage/","title":"Test coverage","text":"<p>To generate the test coverage report, run the following commands in <code>ankaios</code> workspace which is <code>/home/vscode/workspaces/ankaios/</code>:</p> <p>To print out directly into the console:</p> <pre><code>cov test\n</code></pre> <p>Or to produce a report in html:</p> <pre><code>cov test --html\n</code></pre> <p>The script outputs where to find the report html:</p> <pre><code>...\nFinished report saved to /workspaces/ankaios/target/llvm-cov/html\n</code></pre> <p>Note: By the first usage you might be asked for confirmation to install the <code>llvm-tools-preview</code> tool.</p> <p>While writing tests, you may want to execute only the tests in a certain file and check the reached coverage. To do so you can execute:</p> <p>To print out directly into the console:</p> <pre><code>cov test ankaios_server\n</code></pre> <p>Or to produce a report in html:</p> <pre><code>cov test ankaios_server --html\n</code></pre> <p>Once the run is complete, you can check the report to see which lines are not covered yet.</p>"},{"location":"development/unit-verification/","title":"Unit verification","text":"<p>This page defines which tools and processes are used in in this project for the purposes of software unit verification. The unit verification process is performed during implementation phase and is as automated as possible, one exception is the code review which cannot be done automatically. Automated unit test runs are executed by the CI build system as well as during the regular releasing process.</p>"},{"location":"development/unit-verification/#verification-tools-and-procedures","title":"Verification tools and procedures","text":"<p>Ankaios development follows the guidelines specified in the Rust coding guidelines.</p>"},{"location":"development/unit-verification/#code-review","title":"Code review","text":"<p>Code reviews are part of the implementation process and performed before code is merged to the main branch. Contributors create pull requests and request a review s.t. the process can be started. The review is performed by at least one committer who has good knowledge of the area under review. When all applicable review criteria and checklists are passed and reviewer(s) have accepted the change, code can be merged to the main branch.</p>"},{"location":"development/unit-verification/#verification-by-unit-test","title":"Verification by unit test","text":""},{"location":"development/unit-verification/#test-focus-and-goal","title":"Test focus and goal","text":"<p>The objective of the unit test is to confirm the correct internal behavior of a software unit according to the design aspects documented in the SW design. A unit test will test the unit in the target environment by triggering unit methods/functions and verifying the behavior. Stubbed interfaces/mocking techniques can be used to meet the code coverage requirements. This means that unit tests shall be written according to the detailed requirements. Requirement source is SW design.</p>"},{"location":"development/unit-verification/#unit-test-case-naming-convention","title":"Unit test case naming convention","text":"<p>By introducing a naming convention for unit test cases a harmonized test code-base can be achieved. This simplifies reading and understanding the intention of the unit test case. Please see the naming convention defined in Rust coding guidelines.</p>"},{"location":"development/unit-verification/#unit-test-organization","title":"Unit test organization","text":"<p>The unit tests shall be written in the same file as the source code like suggested in the Rust Language Book and shall be prefixed with <code>utest_</code>.</p>"},{"location":"development/unit-verification/#example-for-unit-tests-in-source-file-in-rust","title":"Example for unit tests in source file in Rust","text":"<p>At the end of the file e.g. <code>my_module/src/my_component.rs</code>:</p> <pre><code>...\nfn my_algorithm(input: i32) -&gt; Vec&lt;u8&gt; {\n    ...\n}\n\nasync fn my_async_function(input: i32) -&gt; Vec&lt;u8&gt; {\n    ...\n}\n...\n#[cfg(test)]\nmod tests {\n    ...\n    #[test]\n    fn utest_my_algorithm_returns_empty_array_when_input_is_0_or_negative() {\n        ...\n    }\n\n    #[tokio::test]\n    async fn utest_my_async_function_returns_empty_array_when_input_is_0_or_negative() {\n        ...\n    }\n}\n</code></pre>"},{"location":"development/unit-verification/#test-execution-and-reports","title":"Test Execution and Reports","text":"<p>Unit test cases are executed manually by the developer during implementation phase and later automatically in CI builds. Unit test and coverage reports are generated and stored automatically by the CI build system. If unit test case fails before code is merged to main branch (merge verification), the merge is not allowed until the issue is fixed. If unit test case fails after the code is merged to main branch, it is reported via email and fixed via internal Jira ticket reported by the developer.</p> <p>Regression testing is done by the CI build system.</p>"},{"location":"development/unit-verification/#goals-and-metrics","title":"Goals and Metrics","text":"<p>The following table show how test coverage is currently shown in the coverage report:</p> Goal Metric Red Yellow Green Code coverage &lt;80% &gt;80% 100% <p>Currently there is no proper way of explicitly excluding parts of the code from the test coverage report in order to get to an easily observable value of 100%. The explicitly excluded code would have a corresponding comment stating the reason for excluding it. As this is not possible, we would initially target at least 80% line coverage in each file.</p>"},{"location":"reference/_ankaios.proto/","title":"Protocol Documentation","text":""},{"location":"reference/_ankaios.proto/#table-of-contents","title":"Table of Contents","text":"<ul> <li> <p>ankaios.proto</p> <ul> <li>AddedWorkload</li> <li>AddedWorkload.DependenciesEntry</li> <li>AgentHello</li> <li>ApiVersion</li> <li>CompleteState</li> <li>CompleteStateRequest</li> <li>DeletedWorkload</li> <li>DeletedWorkload.DependenciesEntry</li> <li>Error</li> <li>ExecutionState</li> <li>FromServer</li> <li>Goodbye</li> <li>Request</li> <li>Response</li> <li>State</li> <li>State.WorkloadsEntry</li> <li>Success</li> <li>Tag</li> <li>ToServer</li> <li>UpdateStateRequest</li> <li>UpdateWorkload</li> <li>UpdateWorkloadState</li> <li>Workload</li> <li>Workload.DependenciesEntry</li> <li>WorkloadInstanceName</li> <li> <p>WorkloadState</p> </li> <li> <p>AddCondition</p> </li> <li>AgentDisconnected</li> <li>DeleteCondition</li> <li>Failed</li> <li>NotScheduled</li> <li>Pending</li> <li>Removed</li> <li>Running</li> <li> <p>Succeeded</p> </li> <li> <p>AgentConnection</p> </li> <li>CliConnection</li> </ul> </li> <li> <p>Scalar Value Types</p> </li> </ul> <p></p> <p>Top</p>"},{"location":"reference/_ankaios.proto/#ankaiosproto","title":"ankaios.proto","text":"<p>The Ankaios communication protocol is used in the communcation between the following components:</p> <ol> <li> <p>Ankaios Agent and Ankaios Server,</p> </li> <li> <p>Ankaios CLI and Ankaios Server,</p> </li> <li> <p>Workload and Ankaios Server through the control interface.</p> </li> </ol> <p>The protocol consists of the following top-level message types:</p> <ol> <li> <p>ToServer: agent/cli -&gt; server</p> </li> <li> <p>FromServer: server -&gt; agent/cli</p> </li> </ol> <p></p>"},{"location":"reference/_ankaios.proto/#addedworkload","title":"AddedWorkload","text":"<p>A message containing information about a workload to be added to the Ankaios cluster.</p> Field Type Label Description name string The name of the workload. runtime string The name of the runtime, e.g., podman. dependencies AddedWorkload.DependenciesEntry repeated A list of dependencies to other workloads with their corresponding, expected states. Can be used to enable a synchronized start of a workload. restart bool A flag indicating to restart the workload in case of an intentional or an unintentional stop of the workload. tags Tag repeated A list of tags. runtimeConfig string The configuration information specific to the runtime. <p></p>"},{"location":"reference/_ankaios.proto/#addedworkloaddependenciesentry","title":"AddedWorkload.DependenciesEntry","text":"Field Type Label Description key string value AddCondition"},{"location":"reference/_ankaios.proto/#agenthello","title":"AgentHello","text":"<p>A message to the Ankaios server to register a new agent.</p> Field Type Label Description agentName string A unique agent name. <p></p>"},{"location":"reference/_ankaios.proto/#apiversion","title":"ApiVersion","text":"Field Type Label Description version string The current version of the API."},{"location":"reference/_ankaios.proto/#completestate","title":"CompleteState","text":"<p>A message containing the complete state of the Ankaios system. This is a response to the CompleteStateRequest message.</p> Field Type Label Description format_version ApiVersion The current version of the API. startupState State The State information at the startup of the Ankaios System. desiredState State The state the user wants to reach. workloadStates WorkloadState repeated The current states of the workloads. <p></p>"},{"location":"reference/_ankaios.proto/#completestaterequest","title":"CompleteStateRequest","text":"<p>A message containing a request for the complete/partial state of the Ankaios system. This is usually answered with a CompleteState message.</p> Field Type Label Description fieldMask string repeated A list of symbolic field paths within the State message structure e.g. 'desiredState.workloads.nginx'. <p></p>"},{"location":"reference/_ankaios.proto/#deletedworkload","title":"DeletedWorkload","text":"<p>A message containing information about a workload to be deleted from the Anakaios system.</p> Field Type Label Description name string The name of the workload. dependencies DeletedWorkload.DependenciesEntry repeated A list of dependencies to other workloads with their corresponding, expected states. Can be used to enable a synchronized stop of a workload. <p></p>"},{"location":"reference/_ankaios.proto/#deletedworkloaddependenciesentry","title":"DeletedWorkload.DependenciesEntry","text":"Field Type Label Description key string value DeleteCondition"},{"location":"reference/_ankaios.proto/#error","title":"Error","text":"Field Type Label Description message string"},{"location":"reference/_ankaios.proto/#executionstate","title":"ExecutionState","text":"Field Type Label Description additionalInfo string The additional info contains more detailed information from the runtime regarding the execution state. agentDisconnected AgentDisconnected The exact state of the workload cannot be determined, e.g., because of a broken connection to the responsible agent. pending Pending The workload is going to be started eventually. running Running The workload is operational. succeeded Succeeded The workload has successfully finished its operation. failed Failed The workload has failed or is in a degraded state. notScheduled NotScheduled The workload is not scheduled to run at any agent. This is signalized with an empty agent in the workload specification. removed Removed The workload was removed from Ankaios. This state is used only internally in Ankaios. The outside world removed states are just not there."},{"location":"reference/_ankaios.proto/#fromserver","title":"FromServer","text":"<p>Messages from the Ankaios server to e.g. the Ankaios agent.</p> Field Type Label Description updateWorkload UpdateWorkload A message containing lists of workloads to be added or deleted. updateWorkloadState UpdateWorkloadState A message containing list of workload execution states. response Response A message containing a response to a previous request. <p></p>"},{"location":"reference/_ankaios.proto/#goodbye","title":"Goodbye","text":"<p>A message to the Ankaios server to signalize a client (agent or cli) is shutting down.</p> <p></p>"},{"location":"reference/_ankaios.proto/#request","title":"Request","text":"Field Type Label Description requestId string updateStateRequest UpdateStateRequest A message to Ankaios server to update the State of one or more agent(s). completeStateRequest CompleteStateRequest A message to Ankaios server to request the complete state by the given request id and the optional field mask."},{"location":"reference/_ankaios.proto/#response","title":"Response","text":"Field Type Label Description requestId string success Success error Error completeState CompleteState"},{"location":"reference/_ankaios.proto/#state","title":"State","text":"<p>A message containing the state information.</p> Field Type Label Description workloads State.WorkloadsEntry repeated A mapping from workload names to workload configurations. <p></p>"},{"location":"reference/_ankaios.proto/#stateworkloadsentry","title":"State.WorkloadsEntry","text":"Field Type Label Description key string value Workload"},{"location":"reference/_ankaios.proto/#success","title":"Success","text":""},{"location":"reference/_ankaios.proto/#tag","title":"Tag","text":"<p>A message to store a tag.</p> Field Type Label Description key string The key of the tag. value string The value of the tag. <p></p>"},{"location":"reference/_ankaios.proto/#toserver","title":"ToServer","text":"<p>Messages to the Ankaios server.</p> Field Type Label Description agentHello AgentHello This message is for internal usage only! updateWorkloadState UpdateWorkloadState A message to Ankaios server to update the execution state of a workload. request Request goodbye Goodbye <p></p>"},{"location":"reference/_ankaios.proto/#updatestaterequest","title":"UpdateStateRequest","text":"<p>A message containing a request to update the state of the Ankaios system. The new state is provided as state object. To specify which part(s) of the new state object should be updated a list of update mask (same as field mask) paths needs to be provided.</p> Field Type Label Description newState CompleteState The new state of the Ankaios system. updateMask string repeated A list of symbolic field paths within the state message structure e.g. 'desiredState.workloads.nginx' to specify what to be updated. <p></p>"},{"location":"reference/_ankaios.proto/#updateworkload","title":"UpdateWorkload","text":"<p>A message providing information about the workloads to be added and/or deleted.</p> Field Type Label Description addedWorkloads AddedWorkload repeated A list of messages containing information about a workload to be added by an Ankaios agent. deletedWorkloads DeletedWorkload repeated A list of messages containing information about a workload to be deleted by an Ankaios agent. <p></p>"},{"location":"reference/_ankaios.proto/#updateworkloadstate","title":"UpdateWorkloadState","text":"<p>A message containing the list the workload states.</p> Field Type Label Description workloadStates WorkloadState repeated A list of workload states. <p></p>"},{"location":"reference/_ankaios.proto/#workload","title":"Workload","text":"<p>A message containing the configuration of a workload.</p> Field Type Label Description agent string The name of the owning Agent. restart bool A flag indicating to restart the workload in case of an intentional or an unintentional stop of the workload. dependencies Workload.DependenciesEntry repeated A map of workload names and expected states to enable a synchronized start of the workload. tags Tag repeated A list of tag names. runtime string The name of the runtime e.g. podman. runtimeConfig string The configuration information specific to the runtime. <p></p>"},{"location":"reference/_ankaios.proto/#workloaddependenciesentry","title":"Workload.DependenciesEntry","text":"Field Type Label Description key string value AddCondition"},{"location":"reference/_ankaios.proto/#workloadinstancename","title":"WorkloadInstanceName","text":"Field Type Label Description workloadName string The name of the workload. agentName string The name of the owning Agent. configId string A unique identifier of the runtime config."},{"location":"reference/_ankaios.proto/#workloadstate","title":"WorkloadState","text":"<p>A message containing the information about the workload state.</p> Field Type Label Description instanceName WorkloadInstanceName workloadId string Normally, the Id is provided to the workload by the runtime. The Id may not be available in all execution states. executionState ExecutionState The workload execution state. <p></p>"},{"location":"reference/_ankaios.proto/#addcondition","title":"AddCondition","text":"<p>An enum type describing the expected workload state. Used for dependency management.</p> Name Number Description ADD_COND_RUNNING 0 The workload is operational. ADD_COND_SUCCEEDED 1 The workload has successfully exited. ADD_COND_FAILED 2 The workload has exited with an error or could not be started. <p></p>"},{"location":"reference/_ankaios.proto/#agentdisconnected","title":"AgentDisconnected","text":"<p>The exact state of the workload cannot be determined, e.g., because of a broken connection to the responsible agent.</p> Name Number Description AGENT_DISCONNECTED 0 <p></p>"},{"location":"reference/_ankaios.proto/#deletecondition","title":"DeleteCondition","text":"<p>An enum type describing the conditions for deleting a workload. Used for dependency management, and update strategies.</p> Name Number Description DEL_COND_RUNNING 0 The workload is operational. DEL_COND_NOT_PENDING_NOR_RUNNING 1 The workload is not scheduled or running. <p></p>"},{"location":"reference/_ankaios.proto/#failed","title":"Failed","text":"<p>The workload has failed or is in a degraded state.</p> Name Number Description FAILED_EXEC_FAILED 0 The workload has failed during operation FAILED_UNKNOWN 1 The workload is in an unsupported by Ankaios runtime state. The workload was possibly altered outside of Ankaios. FAILED_LOST 2 The workload cannot be found anymore. The workload was possibly altered outside of Ankaios or was auto-removed by the runtime. FAILED_DELETE_FAILED 8 The deletion of the workload by the runtime failed. <p></p>"},{"location":"reference/_ankaios.proto/#notscheduled","title":"NotScheduled","text":"<p>The workload is not scheduled to run at any agent. This is signalized with an empty agent in the workload specification.</p> Name Number Description NOT_SCHEDULED 0 <p></p>"},{"location":"reference/_ankaios.proto/#pending","title":"Pending","text":"<p>The workload is going to be started eventually.</p> Name Number Description PENDING_INITIAL 0 The workload specification has not yet being received by an agent PENDING_WAITING_TO_START 1 The start of the workload will be triggered once all its dependencies are met. PENDING_STARTING 2 Starting the workload was scheduled at the corresponding runtime. PENDING_STARTING_FAILED 8 The starting of the workload by the runtime failed. <p></p>"},{"location":"reference/_ankaios.proto/#removed","title":"Removed","text":"<p>The workload was removed from Ankaios. This state is used only internally in Ankaios. The outside world removed states are just not there.</p> Name Number Description REMOVED 0 <p></p>"},{"location":"reference/_ankaios.proto/#running","title":"Running","text":"<p>The workload is operational.</p> Name Number Description RUNNING_OK 0 The workload is operational. RUNNING_WAITING_TO_STOP 1 The deletion of the workload will be triggered once neither 'pending' nor 'running' workload depending on it exists. RUNNING_STOPPING 2 Stopping the workload was scheduled at the corresponding runtime. RUNNING_DELETE_FAILED 8 The deletion of the workload by the runtime failed. <p></p>"},{"location":"reference/_ankaios.proto/#succeeded","title":"Succeeded","text":"<p>The workload has successfully finished operation.</p> Name Number Description SUCCEEDED_OK 0 The workload has successfully finished operation. SUCCEEDED_DELETE_FAILED 8 The deletion of the workload by the runtime failed. <p></p>"},{"location":"reference/_ankaios.proto/#agentconnection","title":"AgentConnection","text":"Method Name Request Type Response Type Description ConnectAgent ToServer stream FromServer stream"},{"location":"reference/_ankaios.proto/#cliconnection","title":"CliConnection","text":"Method Name Request Type Response Type Description ConnectCli ToServer stream FromServer stream"},{"location":"reference/_ankaios.proto/#scalar-value-types","title":"Scalar Value Types","text":".proto Type Notes C++ Java Python Go C# PHP Ruby  double double double float float64 double float Float  float float float float float32 float float Float  int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required)  int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum  uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required)  uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required)  sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required)  sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum  fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required)  fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum  sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required)  sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum  bool bool boolean boolean bool bool boolean TrueClass/FalseClass  string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8)  bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)"},{"location":"reference/api/","title":"API","text":"<p>Ankaios offers an API to alter the desired state. The API is constructed with message data structures described in the protocol documentation. Ankaios provides a gRPC API which can be used during development. The provided ank CLI uses this API, but the API can also be used directly. Ankaios also provides the control interface API to the managed workloads which allows workloads to alter the desired/stored state.</p>"},{"location":"reference/complete-state/","title":"Working with CompleteState","text":""},{"location":"reference/complete-state/#completestate","title":"CompleteState","text":"<p>The complete state data structure CompleteState is used for building a request to Ankaios server to change or receive the state of the Ankaios system. It contains the <code>startupState</code> which describes the states provided at the start of the Ankaios system via the startup configuration, the <code>desiredState</code> which describes the state of the Ankaios system the user wants to have and the <code>workloadStates</code> which gives the information about the execution state of all the workloads. By using of CompleteState in conjunction with the object field mask specific parts of the Ankaios state could be retrieved or updated.</p> <p>Example: <code>ank get state</code> returns the complete state of Ankaios system:</p> <pre><code>formatVersion:\n  version: v0.1\nstartupState:\n  workloads: {}\ndesiredState:\n  workloads:\n    hello-pod:\n      agent: agent_B\n      name: hello-pod\n      tags:\n      - key: owner\n        value: Ankaios team\n      dependencies: {}\n      restart: true\n      runtime: podman-kube\n      runtimeConfig: |\n        manifest: |\n          apiVersion: v1\n          kind: Pod\n          metadata:\n            name: hello-pod\n          spec:\n            restartPolicy: Never\n            containers:\n            - name: looper\n              image: alpine:latest\n              command:\n              - sleep\n              - 50000\n            - name: greater\n              image: alpine:latest\n              command:\n              - echo\n              - \"Hello from a container in a pod\"\n    hello1:\n      agent: agent_B\n      name: hello1\n      tags:\n      - key: owner\n        value: Ankaios team\n      dependencies: {}\n      restart: true\n      runtime: podman\n      runtimeConfig: |\n        image: alpine:latest\n        commandOptions: [ \"--rm\"]\n        commandArgs: [ \"echo\", \"Hello Ankaios\"]\n    hello2:\n      agent: agent_B\n      name: hello2\n      tags:\n      - key: owner\n        value: Ankaios team\n      dependencies: {}\n      restart: true\n      runtime: podman\n      runtimeConfig: |\n        image: alpine:latest\n        commandArgs: [ \"echo\", \"Hello Ankaios\"]\n    nginx:\n      agent: agent_A\n      name: nginx\n      tags:\n      - key: owner\n        value: Ankaios team\n      dependencies: {}\n      restart: true\n      runtime: podman\n      runtimeConfig: |\n        image: docker.io/nginx:latest\n        commandOptions: [\"-p\", \"8081:80\"]\nworkloadStates: []\n</code></pre> <p>It is not necessary to provide the whole structure of the the CompleteState data structure when using it in conjunction with the object field mask. It is sufficient to provide the relevant branch of the CompleteState object. As an example, to change the restart behavior of the nginx workload, only the relevant branch of the CompleteState needs to be provided:</p> <pre><code>formatVersion:\n  version: v0.1\ndesiredState:\n  workloads:\n    nginx:\n      restart: false\n</code></pre>"},{"location":"reference/complete-state/#object-field-mask","title":"Object field mask","text":"<p>With the object field mask only specific parts of the Ankaios state could be retrieved or updated. The object field mask can be constructed using the field names of the CompleteState data structure:</p> <pre><code>&lt;top level field name&gt;.&lt;second level field name&gt;.&lt;third level field name&gt;.&lt;...&gt;\n</code></pre> <ol> <li>Example: <code>ank get state desiredState.workloads.nginx</code> returns only the information about nginx workload:</li> </ol> <pre><code> formatVersion:\n   version: v0.1\n desiredState:\n   workloads:\n     nginx:\n       agent: agent_A\n       name: nginx\n       tags:\n       - key: owner\n         value: Ankaios team\n       dependencies: {}\n       restart: true\n       runtime: podman\n       runtimeConfig: |\n         image: docker.io/nginx:latest\n         commandOptions: [\"-p\", \"8081:80\"]\n</code></pre> <ol> <li>Example <code>ank get state desiredState.workloads.nginx.runtimeConfig</code> returns only the runtime configuration of nginx workload:</li> </ol> <pre><code>formatVersion:\n  version: v0.1\ndesiredState:\n  workloads:\n    nginx:\n      runtimeConfig: |\n        image: docker.io/nginx:latest\n        commandOptions: [\"-p\", \"8081:80\"]\n</code></pre> <ol> <li>Example <code>ank set state -f new-state.yaml desiredState.workloads.nginx.restart</code> changes the restart behavior of nginx workload to <code>false</code>:</li> </ol> new-state.yaml<pre><code>formatVersion:\n  version: v0.1\ndesiredState:\n  workloads:\n    nginx:\n      restart: false\n</code></pre>"},{"location":"reference/control-interface/","title":"Control interface","text":"<p>The control interface allows the workload developers to easily integrate the communication between the Ankaios system and their applications.</p> <p>Note</p> <p>The control interface is currently only available for workloads using the <code>podman</code> runtime and not for the <code>podman-kube</code> runtime.</p>"},{"location":"reference/control-interface/#overview","title":"Overview","text":"<pre><code>---\ntitle: Overview\n---\nflowchart TD\n    a1(Ankaios Agent 1)\n    w1(Workload 1)\n    w2(Workload 2)\n    a2(Ankaios Agent 2)\n    w3(Workload 3)\n    w4(Workload 4)\n    s(Ankaios Server)\n\n\n    s &lt;--&gt; a1 &lt;--&gt;|Control Interface| w1 &amp; w2\n    s &lt;--&gt; a2 &lt;--&gt;|Control Interface| w3 &amp; w4</code></pre> <p>The control interface enables a workload to communicate with the Ankaios system by interacting with the Ankaios server through writing/reading communication data to/from the provided FIFO files in the FIFO mount point.</p>"},{"location":"reference/control-interface/#fifo-mount-point","title":"FIFO mount point","text":"<pre><code>---\ntitle: FIFO Mount Point\n---\nflowchart TD\n    a1(Ankaios Agent 1)\n    w1(Workload 1)\n    w2(Workload 2)\n    s(Ankaios Server)\n\n\n    s &lt;--&gt; a1 &lt;--&gt;|\"/run/ankaios/control_interface/{input,output}\"| w1 &amp; w2</code></pre> <p>The control interface relies on FIFO (also known as named pipes) to enable a workload process to communicate with the Ankaios system. For that purpose, Ankaios creates a mount point for each workload to store the FIFO files. At the mount point <code>/run/ankaios/control_interface/</code> the workload developer can find the FIFO files <code>input</code> and <code>output</code> and use them for the communication with the Ankaios server. Ankaios uses its own communication protocol described in protocol documentation as a protobuf IDL which allows the client code to be generated in any programming language supported by the protobuf compiler. The generated client code can then be integrated and used in a workload.</p>"},{"location":"reference/control-interface/#communication-between-ankaios-and-workloads","title":"Communication between Ankaios and workloads","text":"<pre><code>---\ntitle: Communication between Ankaios and a workload\n---\nflowchart TD\n    proto(\"ankaios.proto\")\n    gen_code(\"Generated Client Code\")\n    workload(\"Workload\")\n\n    proto --&gt;|generate code with protoc| gen_code\n    workload--&gt;|uses| gen_code</code></pre> <p>In order to enable the communication between a workload and the Ankaios system, the workload needs to make use of the control interface by sending and processing serialized messages defined in <code>ankaios.proto</code> via writing to and reading from the provided FIFO files <code>output</code> and <code>input</code> found in the mount point <code>/run/ankaios/control_interface/</code>. By using the protobuf compiler (protoc) code in any programming language supported by the protobuf compiler can be generated. The generated code contains functions for serializing and deserializing the messages to and from the Protocol Buffers binary format.</p>"},{"location":"reference/control-interface/#length-delimited-protobuf-message-layout","title":"Length-delimited protobuf message layout","text":"<p>The messages are encoded using the length-delimited wire type format and layout inside the FIFO file according to the following visualization:</p> <p></p> <p>Every protobuf message is prefixed with its byte length telling the reader how much bytes to read to consume the protobuf message. The byte length has a dynamic length and is encoded as VARINT.</p>"},{"location":"reference/control-interface/#control-interface-examples","title":"Control interface examples","text":"<p>The subfolder <code>examples</code> inside the Ankaios repository contains example workload applications in various programming languages that are using the control interface. They demonstrate how to easily use the control interface in self-developed workloads. All examples share the same behavior regardless of the programming language and are simplified to focus on the usage of the control interface. Please note that the examples are not are not optimized for production usage.</p> <p>The following sections showcase in Rust some important parts of the communication with the Ankaios cluster using the control interface. The same concepts are also used in all of the example workload applications.</p>"},{"location":"reference/control-interface/#sending-request-message-from-a-workload-to-ankaios-server","title":"Sending request message from a workload to Ankaios server","text":"<p>To send out a request message from the workload to the Ankaios Server the request message needs to be serialized using the generated serializing function, then encoded as length-delimited protobuf message and then written directly into the <code>output</code> FIFO file. The type of request message is ToServer.</p> <pre><code>---\ntitle: Send request message via control interface\n---\nflowchart TD\n    begin([Start])\n    req_msg(Fill ToServer message)\n    ser_msg(Serialize ToServer message using the generated serializing function)\n    enc_bytes(Encode as length-delimited varint)\n    output(\"Write encoded bytes to /run/ankaios/control_interface/output\")\n    fin([end])\n\n    begin --&gt; req_msg\n    req_msg --&gt; ser_msg\n    ser_msg --&gt;enc_bytes\n    enc_bytes --&gt; output\n    output --&gt; fin</code></pre> <p>Code snippet in Rust for sending request message via control interface:</p> <pre><code>use api::proto;\nuse prost::Message;\nuse std::{collections::HashMap, fs::File, io::Write, path::Path};\n\nconst ANKAIOS_CONTROL_INTERFACE_BASE_PATH: &amp;str = \"/run/ankaios/control_interface\";\n\nfn create_update_workload_request() -&gt; proto::ToServer {\n    let new_workloads = HashMap::from([(\n        \"dynamic_nginx\".to_string(),\n        proto::Workload {\n            runtime: \"podman\".to_string(),\n            agent: \"agent_A\".to_string(),\n            restart: false,\n            tags: vec![proto::Tag {\n                key: \"owner\".to_string(),\n                value: \"Ankaios team\".to_string(),\n            }],\n            runtime_config: \"image: docker.io/library/nginx\\ncommandOptions: [\\\"-p\\\", \\\"8080:80\\\"]\"\n                .to_string(),\n            dependencies: HashMap::new(),\n        },\n    )]);\n\n    proto::ToServer {\n        to_server_enum: Some(proto::to_server::ToServerEnum::Request(proto::Request {\n            request_id: \"request_id\".to_string(),\n            request_content: Some(proto::request::RequestContent::UpdateStateRequest(\n                proto::UpdateStateRequest {\n                    new_state: Some(proto::CompleteState {\n                        format_version: Some(proto::ApiVersion {\n                            version: \"v0.1\".to_string(),\n                        }),\n                        desired_state: Some(proto::State {\n                            workloads: new_workloads,\n                        }),\n                        ..Default::default()\n                    }),\n                    update_mask: vec![\"desiredState.workloads.dynamic_nginx\".to_string()],\n                },\n            )),\n        })),\n    }\n}\n\nfn write_to_control_interface() {\n    let pipes_location = Path::new(ANKAIOS_CONTROL_INTERFACE_BASE_PATH);\n    let sc_req_fifo = pipes_location.join(\"output\");\n\n    let mut sc_req = File::create(&amp;sc_req_fifo).unwrap();\n\n    let protobuf_update_workload_request = create_update_workload_request();\n\n    println!(\"{}\", &amp;format!(\"Sending UpdateStateRequest containing details for adding the dynamic workload \\\"dynamic_nginx\\\": {:#?}\", protobuf_update_workload_request));\n\n    sc_req\n        .write_all(&amp;protobuf_update_workload_request.encode_length_delimited_to_vec())\n        .unwrap();\n}\n\nfn main() {\n    write_to_control_interface();\n}\n</code></pre>"},{"location":"reference/control-interface/#processing-response-message-from-ankaios-server","title":"Processing response message from Ankaios server","text":"<p>To process a response message from the Ankaios Server the workload needs to read out the bytes from the <code>input</code> FIFO file. As the bytes are encoded as length-delimited protobuf message with a variable length, the length needs to be decoded and extracted first. Then the length can be used to decode and deserialize the read bytes to a response message object for further processing. The type of the response message is FromServer.</p> <pre><code>---\ntitle: Read response message via control interface\n---\nflowchart TD\n    begin([Start])\n    input(\"Read bytes from /run/ankaios/control_interface/input\")\n    dec_length(Get length from read length delimited varint encoded bytes)\n    deser_msg(Decode and deserialize FromServer message using decoded length and the generated functions)\n    further_processing(Process FromServer message object)\n    fin([end])\n\n    begin --&gt; input\n    input --&gt; dec_length\n    dec_length --&gt; deser_msg\n    deser_msg --&gt; further_processing\n    further_processing --&gt; fin</code></pre> <p>Code Snippet in Rust for reading response message via control interface:</p> <pre><code>use api::proto;\nuse prost::Message;\nuse std::{fs::File, io, io::Read, path::Path};\n\nconst ANKAIOS_CONTROL_INTERFACE_BASE_PATH: &amp;str = \"/run/ankaios/control_interface\";\nconst MAX_VARINT_SIZE: usize = 19;\n\nfn read_varint_data(file: &amp;mut File) -&gt; Result&lt;[u8; MAX_VARINT_SIZE], io::Error&gt; {\n    let mut res = [0u8; MAX_VARINT_SIZE];\n    let mut one_byte_buffer = [0u8; 1];\n    for item in res.iter_mut() {\n        file.read_exact(&amp;mut one_byte_buffer)?;\n        *item = one_byte_buffer[0];\n        // check if most significant bit is set to 0 if so it is the last byte to be read\n        if *item &amp; 0b10000000 == 0 {\n            break;\n        }\n    }\n    Ok(res)\n}\n\nfn read_protobuf_data(file: &amp;mut File) -&gt; Result&lt;Box&lt;[u8]&gt;, io::Error&gt; {\n    let varint_data = read_varint_data(file)?;\n    let mut varint_data = Box::new(&amp;varint_data[..]);\n\n    // determine the exact size for exact reading of the bytes later by decoding the varint data\n    let size = prost::encoding::decode_varint(&amp;mut varint_data)? as usize;\n\n    let mut buf = vec![0; size];\n    file.read_exact(&amp;mut buf[..])?; // read exact bytes from file\n    Ok(buf.into_boxed_slice())\n}\n\nfn read_from_control_interface() {\n    let pipes_location = Path::new(ANKAIOS_CONTROL_INTERFACE_BASE_PATH);\n    let ex_req_fifo = pipes_location.join(\"input\");\n\n    let mut ex_req = File::open(&amp;ex_req_fifo).unwrap();\n\n    loop {\n        if let Ok(binary) = read_protobuf_data(&amp;mut ex_req) {\n            let proto = proto::FromServer::decode(&amp;mut Box::new(binary.as_ref()));\n\n            println!(\"{}\", &amp;format!(\"Receiving FromServer containing the workload states of the current state: {:#?}\", proto));\n        }\n    }\n}\n\nfn main() {\n    read_from_control_interface();\n}\n</code></pre>"},{"location":"reference/glossary/","title":"Glossary","text":"<p>This glossary is intended to be a comprehensive, uniform list of Ankaios terminology. It consists of technical terms specific to Ankaios, as well as more general terms that provide useful context.</p>"},{"location":"reference/glossary/#node","title":"Node","text":"<p>A machine, either physical or virtual, that provides the necessary prerequisites (e.g. OS) to run an Ankaios server and/or agent.</p>"},{"location":"reference/glossary/#runtime","title":"Runtime","text":"<p>The base an which a workload can be started. For OCI container this is a container runtime or engine. For native applications the runtime is the OS itself.</p>"},{"location":"reference/glossary/#workload","title":"Workload","text":"<p>A functionality that the Ankaios orchestrator can manage (e.g. start, stop). A workload could be packed inside an OCI container (e.g. Podman container) or could also be just a native program (native workload). Ankaios is build to be extensible for different workload types by adding support for other runtimes.</p>"},{"location":"reference/glossary/#container","title":"Container","text":"<p>A container is a lightweight, standalone, executable software package that includes everything needed to run an application, including the binaries, runtime, system libraries and dependencies. Containers provide a consistent and isolated environment for applications to run, ensuring that they behave consistently across different computing environments, from development to testing to production.</p>"},{"location":"reference/glossary/#podman-container","title":"Podman container","text":"<p>A Podman container refers to a container managed by Podman, which is an open-source container engine similar to Docker. Podman aims to provide a simple and secure container management solution for developers and system administrators.</p>"},{"location":"reference/glossary/#native-workload","title":"Native workload","text":"<p>An application developed specifically for a particular platform or operating system (OS). It is designed to run directly on the target platform without the need for bringing in any additional translation or emulation layers.</p>"},{"location":"reference/startup-configuration/","title":"Startup configuration","text":"<p>In the Ankaios system it is mandatory to specify all the nodes and workloads that are going to be ran. Currently the startup configuration is provided as a file which is in YAML file format and can be passed to the Ankaios server through a command line argument. Depending on the demands towards Ankaios, the startup configuration can later be provided in a different way.</p>"},{"location":"reference/startup-configuration/#configuration-structure","title":"Configuration structure","text":"<p>The startup configuration is composed of a list of workload specifications within the <code>workloads</code> object. A workload specification must contain the following information:</p> <ul> <li><code>workload name</code>(via field key), specify the workload name to identify the workload in the Ankaios system.</li> <li><code>runtime</code>, specify the type of the runtime. Currently supported values are <code>podman</code> and <code>podman-kube</code>.</li> <li><code>agent</code>, specify the name of the owning agent which is going to execute the workload.</li> <li><code>restart</code>, specify if the workload shall be restarted when it exits (not implemented yet).</li> <li><code>tags</code>, specify a list of <code>key</code> <code>value</code>  pairs.</li> <li><code>runtimeConfig</code>, specify as a string the configuration for the runtime whose configuration structure is specific for each runtime, e.g., for <code>podman</code> runtime the PodmanRuntimeConfig is used.</li> </ul> <p>Example <code>startup-config.yaml</code> file:</p> <pre><code>workloads:\n  nginx: # this is used as the workload name which is 'nginx'\n    runtime: podman\n    agent: agent_A\n    restart: true\n    tags:\n      - key: owner\n        value: Ankaios team\n    runtimeConfig: |\n      image: docker.io/nginx:latest\n      commandOptions: [\"-p\", \"8081:80\"]\n</code></pre>"},{"location":"reference/startup-configuration/#podmanruntimeconfig","title":"PodmanRuntimeConfig","text":"<p>The runtime configuration for the <code>podman</code> runtime is specified as follows:</p> <pre><code>generalOptions: [&lt;comma&gt;, &lt;separated&gt;, &lt;options&gt;]\nimage: &lt;registry&gt;/&lt;image name&gt;:&lt;version&gt;\ncommandOptions: [&lt;comma&gt;, &lt;separated&gt;, &lt;options&gt;]\ncommandArgs: [&lt;comma&gt;, &lt;separated&gt;, &lt;arguments&gt;]\n</code></pre> <p>where each attribute is passed directly to <code>podman run</code>.</p> <p>If we take as an example the <code>podman run</code> command:</p> <p><code>podman --events-backend file run --env VAR=able docker.io/alpine:latest echo Hello!</code></p> <p>it would translate to the following runtime configuration:</p> <pre><code>generalOptions: [\"--events-backend\", \"file\"]\nimage: docker.io/alpine:latest\ncommandOptions: [\"--env\", \"VAR=able\"]\ncommandArgs: [\"echo\", \"Hello!\"]\n</code></pre>"},{"location":"reference/startup-configuration/#podmankuberuntimeconfig","title":"PodmanKubeRuntimeConfig","text":"<p>The runtime configuration for the <code>podman-kube</code> runtime is specified as follows:</p> <pre><code>generalOptions: [&lt;comma&gt;, &lt;separated&gt;, &lt;options&gt;]\nplay_options: [&lt;comma&gt;, &lt;separated&gt;, &lt;options&gt;]\ndown_options: [&lt;comma&gt;, &lt;separated&gt;, &lt;options&gt;]\nmanifest: &lt;string containing the K8s manifest&gt;\n</code></pre> <p>where each attribute is passed directly to <code>podman play kube</code>.</p> <p>If we take as an example the <code>podman play kube</code> command:</p> <p><code>podman --events-backend file play kube --userns host manifest.yaml</code></p> <p>and the corresponding command for deleting the manifest file:</p> <p><code>podman --events-backend file play kube manifest.yaml --down --force</code></p> <p>they would translate to the following runtime configuration:</p> <pre><code>generalOptions: [\"--events-backend\", \"file\"]\nplay_options: [\"--userns\", \"host\"]\ndown_options: [\"--force\"]\nmanifest: &lt;contents of manifest.yaml&gt;\n</code></pre>"},{"location":"usage/installation/","title":"Installation","text":"<p>Ankaios has been tested with the following Linux distributions. Others might work as well but have not been tested.</p> <ul> <li>Ubuntu 23.04</li> <li>Ubuntu 22.04 LTS</li> <li>Ubuntu 20.04 LTS</li> </ul>"},{"location":"usage/installation/#pre-requisites","title":"Pre-requisites","text":"<p>Ankaios currently requires a Linux OS and is available for x86_64 and arm64 targets. Podman needs to be installed as this is used as container runtime (see Podman installation instructions). For using the <code>podman</code> runtime, Podman version 3.4.2 is sufficient but the <code>podman-kube</code> runtime requires at least Podman version 4.3.1.</p>"},{"location":"usage/installation/#installation-methods","title":"Installation methods","text":"<p>There a different ways to install Ankaios.</p>"},{"location":"usage/installation/#setup-with-script","title":"Setup with script","text":"<p>The recommended way to install Ankaios is using the installation script. To install the latest release version of Ankaios, please run the following command:</p> <pre><code>curl -sfL https://github.com/eclipse-ankaios/ankaios/releases/latest/download/install.sh | bash -\n</code></pre> <p>The installation process automatically detects the platform and downloads the appropriate binaries. The default installation path for the binaries is <code>/usr/local/bin</code> but can be changed. The installation also creates systemd unit files and an uninstall script.</p> <p>Supported platforms: <code>linux/amd64</code>, <code>linux/arm64</code></p> <p>Note</p> <p>The script requires root privileges to install the pre-built binaries into the default installation path <code>/usr/local/bin</code> and also for systemd integration. You can set a custom installation path and disable systemd unit file generation if only non-root privileges are available.</p> <p>The following table shows the optional arguments that can be passed to the script:</p> Supported parameters Description -v &lt;version&gt; e.g. <code>v0.1.0</code>, default: latest version -i &lt;install-path&gt; File path where Ankaios will be installed, default: <code>/usr/local/bin</code> -t &lt;install-type&gt; Installation type for systemd integration: <code>server</code>, <code>agent</code>, <code>none</code> or <code>both</code> (default) -s &lt;server-options&gt; Options which will be passed to the Ankaios server. Default <code>--startup-config /etc/ankaios/state.yaml</code> -a &lt;agent-options&gt; Options which will be passed to the Ankaios agent. Default <code>--name agent_A</code> <p>To install a specific version run the following command and substitute <code>&lt;version&gt;</code> with a specific version tag e.g. <code>v0.1.0</code>:</p> <pre><code>curl -sfL https://github.com/eclipse-ankaios/ankaios/releases/download/&lt;version&gt;/install.sh | bash -s -- -v &lt;version&gt;\n</code></pre> <p>For available versions see the list of releases.</p>"},{"location":"usage/installation/#uninstall-ankaios","title":"Uninstall Ankaios","text":"<p>If Ankaios has been installed with the installation script, it can be uninstalled with:</p> <pre><code>ank-uninstall.sh\n</code></pre> <p>The folder <code>/etc/ankaios</code> will remain.</p>"},{"location":"usage/installation/#manual-download-of-binaries","title":"Manual download of binaries","text":"<p>As an alternative to the installation script, the pre-built binaries can be downloaded manually from the Ankaios repository here. This is useful if the automatic detection of the platform is failing in case of <code>uname</code> system command is not allowed or supported on the target.</p>"},{"location":"usage/installation/#build-from-source","title":"Build from source","text":"<p>For building Ankaios from source see Build.</p>"},{"location":"usage/quickstart/","title":"Quickstart","text":"<p>If you have not installed Ankaios, please follow the instructions here. The following examples assumes that the installation script has been used with default options.</p> <p>You can start workloads in Ankaios in a number of ways. For example, you can define a file with the startup configuration and use systemd to start Ankaios. The startup configuration file contains all of the workloads and their configuration that you want to be started by Ankaios.</p> <p>Let's modify the default config which is stored in <code>/etc/ankaios/state.yaml</code>:</p> <pre><code>workloads:\n  nginx:\n    runtime: podman\n    agent: agent_A\n    restart: true\n    tags:\n      - key: owner\n        value: Ankaios team\n    runtimeConfig: |\n      image: docker.io/nginx:latest\n      commandOptions: [\"-p\", \"8081:80\"]\n</code></pre> <p>Then we can start the Ankaios server:</p> <pre><code>sudo systemctl start ank-server\n</code></pre> <p>The Ankaios server will read the config but detect that no agent with the name <code>agent_A</code> is available that could start the workload, see logs with:</p> <pre><code>journalctl -t ank-server\n</code></pre> <p>Now let's start an agent:</p> <pre><code>sudo systemctl start ank-agent\n</code></pre> <p>This Ankaios agent will run the workload that has been assigned to it. We can use the Ankaios CLI to check the current state:</p> <pre><code>ank get state\n</code></pre> <p>which creates:</p> <pre><code>formatVersion:\n  version: v0.1\nstartupState:\n  workloads: {}\ndesiredState:\n  workloads:\n    nginx:\n      agent: agent_A\n      name: nginx\n      tags:\n      - key: owner\n        value: Ankaios team\n      dependencies: {}\n      restart: true\n      runtime: podman\n      runtimeConfig: |\n        image: docker.io/nginx:latest\n        commandOptions: [\"-p\", \"8081:80\"]\nworkloadStates:\n- instanceName:\n    agentName: agent_A\n    workloadName: nginx\n    hash: 7d6ea2b79cea1e401beee1553a9d3d7b5bcbb37f1cfdb60db1fbbcaa140eb17d\n  workloadId: 90996c5fb5393c07c784d5f27ea9c29a81e5604f48e6592913bfac2c89fe1413\n  executionState:\n    state: Running\n    subState: Ok\n    additionalInfo: ''\n</code></pre> <p>or</p> <pre><code>ank get workloads\n</code></pre> <p>which results in:</p> <pre><code>WORKLOAD NAME   AGENT     RUNTIME   EXECUTION STATE   ADDITIONAL INFO\n nginx           agent_A   podman    Running(Ok)\n</code></pre> <p>Ankaios also supports adding and removing workloads dynamically. To add another workload call:</p> <pre><code>ank run workload \\\nhelloworld \\\n--runtime podman \\\n--agent agent_A \\\n--config 'image: docker.io/busybox:1.36\ncommandOptions: [ \"-e\", \"MESSAGE=Hello World\"]\ncommandArgs: [ \"sh\", \"-c\", \"echo $MESSAGE\"]'\n</code></pre> <p>We can check the state again with <code>ank get state</code> and see, that the workload <code>helloworld</code> has been added to <code>desiredState.workloads</code> and the execution state is available in <code>workloadStates</code>.</p> <p>As the workload had a one time job its state is <code>Succeeded(Ok)</code> and we can delete it from the state again with:</p> <pre><code>ank delete workload helloworld\n</code></pre> <p>For next steps see the reference documentation for the startup configuration including the <code>podman-kube</code> runtime and also working with the complete state data structure.</p>"}]}